openapi: 3.0.3
info:
  title: Apple Floodgate LLM API
  description: |
    Apple Floodgate is an internal AI proxy service that provides access to various AI models through an OpenAI-compatible API. 
    This specification documents the complete API for implementing Floodgate support in client applications.
    
    ## Key Features
    - OpenAI-compatible chat completions API
    - Function/tool calling support with multi-turn conversations
    - OAuth2 authentication via Apple Connect
    - Support for various AI models (including Claude models from Anthropic)
    - MCP (Model Context Protocol) tool integration
    
    ## Authentication
    Floodgate uses OAuth2 with PKCE via the `appleconnect` command-line tool. Clients must obtain tokens using:
    ```bash
    /usr/local/bin/appleconnect getToken -C hvys3fcwcteqrvw3qzkvtk86viuoqv \
      --token-type=oauth --interactivity-type=none -E prod -G pkce \
      -o "openid,dsid,accountname,profile,groups"
    ```
    
    ## Tool Calling Workflow
    1. Send messages with available tools
    2. Model responds with tool_calls if tools are needed
    3. Execute tools and send results as role="tool" messages
    4. Model processes results and provides final response
    
    ## MCP Integration
    Tools can be dynamically discovered from MCP servers and presented to Floodgate using the standard tool format.
    MCP tools are namespaced (e.g., "mcp_server_name::tool_name") to avoid conflicts.
  version: 1.0.0
  contact:
    name: Apple Internal AI Services
  license:
    name: Apple Internal Use Only

servers:
  - url: https://floodgate.g.apple.com/api/openai/v1
    description: Apple Floodgate Production Server

security:
  - BearerAuth: []

paths:
  /models:
    get:
      summary: List Available Models
      description: |
        Retrieve a list of available AI models. Floodgate provides access to various AI models from different providers.
        
        **Model Naming**: Model IDs can vary depending on the provider and configuration. Common examples include:
        - Claude models: `aws:anthropic.claude-{version}-{date}-v{revision}:0`
        - Other models may use different naming conventions entirely
        
        Always use the actual model ID returned by this endpoint rather than assuming a specific format.
      operationId: listModels
      responses:
        '200':
          description: Successful response with list of available models
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelsResponse'
              example:
                data:
                  - id: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
                    object: "model"
                    created: 1714780800
                    owned_by: "anthropic"
                  - id: "aws:anthropic.claude-3-5-sonnet-20241022-v2:0"
                    object: "model"
                    created: 1729555200
                    owned_by: "anthropic"
                  - id: "custom-model-v1"
                    object: "model"
                    created: 1709251200
                    owned_by: "apple"
                  - id: "gpt-4o"
                    object: "model"
                    created: 1709251200
                    owned_by: "openai"
        '401':
          $ref: '#/components/responses/UnauthorizedError'
        '403':
          $ref: '#/components/responses/ForbiddenError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/InternalServerError'

  /chat/completions:
    post:
      summary: Create Chat Completion
      description: |
        Generate a chat completion using the specified model. Supports multi-turn conversations,
        function/tool calling, and system prompts. Compatible with OpenAI chat completions format.
        
        ## Tool Calling Flow
        When tools are provided, the model may respond with `tool_calls` instead of content.
        Execute the requested tools and send results back as `role: "tool"` messages with the 
        corresponding `tool_call_id` to continue the conversation.
        
        ## MCP Tool Support
        Tools discovered from MCP servers can be included in the tools array. The client should:
        1. Connect to MCP servers and discover available tools
        2. Convert MCP tool schemas to OpenAI function format
        3. Execute MCP tools when called by the model
        4. Return results in the standard tool response format
      operationId: createChatCompletion
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
            examples:
              simple_chat:
                summary: Simple chat message
                value:
                  model: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
                  messages:
                    - role: "user"
                      content: "Hello, how are you?"
                  max_tokens: 1000
                  temperature: 0.7
              
              with_tools:
                summary: Chat with tools available
                value:
                  model: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
                  messages:
                    - role: "user"
                      content: "What's the weather like in San Francisco?"
                  tools:
                    - type: "function"
                      function:
                        name: "get_weather"
                        description: "Get current weather for a location"
                        parameters:
                          type: "object"
                          properties:
                            location:
                              type: "string"
                              description: "City name"
                          required: ["location"]
                  max_tokens: 1000
              
              tool_response:
                summary: Continuing conversation with tool results
                value:
                  model: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
                  messages:
                    - role: "user"
                      content: "What's the weather like in San Francisco?"
                    - role: "assistant"
                      content: ""
                      tool_calls:
                        - id: "call_123"
                          type: "function"
                          function:
                            name: "get_weather"
                            arguments: '{"location": "San Francisco"}'
                    - role: "tool"
                      content: "Sunny, 72Â°F with light breeze"
                      tool_call_id: "call_123"
                  max_tokens: 1000
              
              mcp_tools:
                summary: Using MCP-discovered tools
                value:
                  model: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
                  messages:
                    - role: "user"
                      content: "List files in the current directory"
                  tools:
                    - type: "function"
                      function:
                        name: "filesystem::list_directory"
                        description: "List files and directories (from MCP filesystem server)"
                        parameters:
                          type: "object"
                          properties:
                            path:
                              type: "string"
                              description: "Directory path to list"
                          required: ["path"]
      x-code-samples:
        - lang: JavaScript
          label: "Complete Tool Calling Flow (like Flood app)"
          source: |-
            // Complete implementation matching flood app pattern
            import { MCPClientManager } from './mcpClientManager.js';
            import { executeTool } from './toolController.js';

            class FloodgateClient {
              constructor() {
                this.baseUrl = 'https://floodgate.g.apple.com/api/openai/v1';
                this.token = null;
                this.mcpManager = new MCPClientManager();
              }

              async getToken() {
                const { spawn } = require('child_process');
                return new Promise((resolve, reject) => {
                  const cmd = spawn('/usr/local/bin/appleconnect', [
                    'getToken', '-C', 'hvys3fcwcteqrvw3qzkvtk86viuoqv',
                    '--token-type=oauth', '--interactivity-type=none',
                    '-E', 'prod', '-G', 'pkce',
                    '-o', 'openid,dsid,accountname,profile,groups'
                  ]);
                  
                  let output = '';
                  cmd.stdout.on('data', (data) => { output += data.toString(); });
                  cmd.on('close', (code) => {
                    if (code !== 0) {
                      reject(new Error('Failed to get token'));
                      return;
                    }
                    const tokens = output.trim().split(/\s+/);
                    resolve(tokens[tokens.length - 1]);
                  });
                });
              }

              async chatWithTools(messages, availableTools = []) {
                if (!this.token) {
                  this.token = await this.getToken();
                }

                // Initialize MCP manager and get MCP tools
                await this.mcpManager.initialize();
                const mcpTools = this.mcpManager.getAvailableTools();
                
                // Combine local and MCP tools
                const allTools = [...availableTools, ...mcpTools];

                const response = await fetch(`${this.baseUrl}/chat/completions`, {
                  method: 'POST',
                  headers: {
                    'Authorization': `Bearer ${this.token}`,
                    'Content-Type': 'application/json'
                  },
                  body: JSON.stringify({
                    model: 'aws:anthropic.claude-sonnet-4-20250514-v1:0',
                    messages,
                    tools: allTools,
                    max_tokens: 4000
                  })
                });

                if (response.status === 401) {
                  // Token expired, refresh and retry
                  this.token = await this.getToken();
                  return this.chatWithTools(messages, availableTools);
                }

                if (!response.ok) {
                  throw new Error(`HTTP error! status: ${response.status}`);
                }

                const completion = await response.json();
                const choice = completion.choices[0];

                if (choice.finish_reason === 'tool_calls') {
                  // Execute tools and continue conversation
                  const toolResults = await Promise.all(
                    choice.message.tool_calls.map(async (toolCall) => {
                      try {
                        // Use unified tool controller (handles both local and MCP tools)
                        const result = await executeTool(
                          toolCall.function.name, 
                          JSON.parse(toolCall.function.arguments)
                        );
                        
                        return {
                          role: 'tool',
                          content: typeof result === 'string' ? result : JSON.stringify(result),
                          tool_call_id: toolCall.id
                        };
                      } catch (error) {
                        return {
                          role: 'tool',
                          content: `Error: ${error.message}`,
                          tool_call_id: toolCall.id
                        };
                      }
                    })
                  );

                  // Continue conversation with tool results
                  return this.chatWithTools([
                    ...messages,
                    choice.message,
                    ...toolResults
                  ], availableTools);
                }

                return {
                  content: choice.message.content,
                  usage: completion.usage
                };
              }
            }

            // Usage example
            const client = new FloodgateClient();
            
            const result = await client.chatWithTools([
              { role: 'user', content: 'List files in the current directory and tell me about package.json' }
            ]);
            
            console.log(result.content);
        
        - lang: JavaScript  
          label: "Simple Tool Execution"
          source: |-
            // Simple tool calling example
            async function executeToolCall(toolCall) {
              const { name, arguments: args } = toolCall.function;
              
              // Parse arguments
              const params = JSON.parse(args);
              
              // Route to appropriate tool handler
              switch (name) {
                case 'filesystem::read_file':
                  const fs = require('fs').promises;
                  return await fs.readFile(params.path, 'utf8');
                  
                case 'weather::get_current':
                  // Call weather API
                  const response = await fetch(`https://api.weather.com/v1/current?location=${params.location}`);
                  return await response.text();
                  
                case 'mcp_server::custom_tool':
                  // Execute MCP tool via client
                  const mcpClient = mcpClients.get('mcp_server');
                  const result = await mcpClient.callTool('custom_tool', params);
                  return result.content[0].text;
                  
                default:
                  throw new Error(`Unknown tool: ${name}`);
              }
            }
      
        - lang: JavaScript
          label: "MCP Integration Pattern"  
          source: |-
            // MCP tool discovery and integration (flood app pattern)
            import { Client } from '@modelcontextprotocol/sdk/client/index.js';
            import { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';

            class MCPClientManager {
              constructor() {
                this.clients = new Map();
                this.tools = new Map();
                this.initialized = false;
              }

              async initialize() {
                if (this.initialized) return;

                // Load MCP server configurations
                const mcpServers = {
                  filesystem: {
                    command: 'npx',
                    args: ['-y', '@modelcontextprotocol/server-filesystem', '/path/to/files']
                  },
                  weather: {
                    command: 'python',
                    args: ['-m', 'weather_mcp_server']
                  }
                };

                // Connect to each server
                for (const [name, config] of Object.entries(mcpServers)) {
                  try {
                    await this.connectToServer(name, config);
                  } catch (error) {
                    console.error(`Failed to connect to MCP server ${name}:`, error);
                  }
                }

                this.initialized = true;
              }

              async connectToServer(serverName, config) {
                const transport = new StdioClientTransport({
                  command: config.command,
                  args: config.args || []
                });

                const client = new Client({
                  name: `flood-client`,
                  version: "1.0.0"
                }, {
                  capabilities: {
                    tools: {}
                  }
                });

                await client.connect(transport);
                this.clients.set(serverName, client);

                // Discover tools from this server
                const toolsResponse = await client.listTools();
                for (const tool of toolsResponse.tools) {
                  const namespacedName = `${serverName}::${tool.name}`;
                  this.tools.set(namespacedName, {
                    serverName,
                    tool,
                    client
                  });
                }
              }

              getAvailableTools() {
                return Array.from(this.tools.entries()).map(([name, { tool }]) => ({
                  type: 'function',
                  function: {
                    name,
                    description: tool.description,
                    parameters: tool.inputSchema
                  }
                }));
              }

              async executeTool(toolName, params) {
                const toolInfo = this.tools.get(toolName);
                if (!toolInfo) {
                  throw new Error(`Tool ${toolName} not found`);
                }

                const result = await toolInfo.client.callTool(toolInfo.tool.name, params);
                return result.content[0].text;
              }
            }
      responses:
        '200':
          description: Successful completion response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
              examples:
                text_response:
                  summary: Simple text response
                  value:
                    id: "chatcmpl-123abc"
                    object: "chat.completion"
                    created: 1694268190
                    model: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
                    choices:
                      - index: 0
                        message:
                          role: "assistant"
                          content: "Hello! I'm doing well, thank you for asking. How can I help you today?"
                        finish_reason: "stop"
                    usage:
                      prompt_tokens: 10
                      completion_tokens: 20
                      total_tokens: 30
                
                tool_call_response:
                  summary: Response requesting tool execution
                  value:
                    id: "chatcmpl-456def"
                    object: "chat.completion"
                    created: 1694268200
                    model: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
                    choices:
                      - index: 0
                        message:
                          role: "assistant"
                          content: ""
                          tool_calls:
                            - id: "call_abc123"
                              type: "function"
                              function:
                                name: "get_weather"
                                arguments: '{"location": "San Francisco"}'
                        finish_reason: "tool_calls"
                    usage:
                      prompt_tokens: 50
                      completion_tokens: 15
                      total_tokens: 65
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/UnauthorizedError'
        '403':
          $ref: '#/components/responses/ForbiddenError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '451':
          $ref: '#/components/responses/ContentFilteredError'
        '500':
          $ref: '#/components/responses/InternalServerError'
        '503':
          $ref: '#/components/responses/ServiceUnavailableError'

components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      description: |
        OAuth2 bearer token obtained via Apple Connect. Use the appleconnect command:
        ```bash
        /usr/local/bin/appleconnect getToken -C hvys3fcwcteqrvw3qzkvtk86viuoqv \
          --token-type=oauth --interactivity-type=none -E prod -G pkce \
          -o "openid,dsid,accountname,profile,groups"
        ```

  schemas:
    ModelsResponse:
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
      required:
        - data

    Model:
      type: object
      properties:
        id:
          type: string
          description: |
            Model identifier. Format varies by provider and configuration.
            Examples: "aws:anthropic.claude-sonnet-4-20250514-v1:0", "gpt-4o", "custom-model-v1"
          example: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
        object:
          type: string
          enum: ["model"]
          example: "model"
        created:
          type: integer
          description: Unix timestamp of model creation
          example: 1714780800
        owned_by:
          type: string
          description: Organization that owns the model (e.g., "anthropic", "openai", "apple")
          example: "anthropic"
      required:
        - id
        - object
        - created
        - owned_by

    ChatCompletionRequest:
      type: object
      properties:
        model:
          type: string
          description: Model ID to use for completion
          example: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatMessage'
          description: List of messages in the conversation
          minItems: 1
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
          description: |
            Available tools/functions the model can call. Include MCP-discovered tools here.
            Tools from MCP servers should be namespaced (e.g., "server_name::tool_name").
        max_tokens:
          type: integer
          description: Maximum number of tokens to generate
          minimum: 1
          maximum: 200000
          example: 1000
        temperature:
          type: number
          description: Sampling temperature (0-2)
          minimum: 0
          maximum: 2
          example: 0.7
        top_p:
          type: number
          description: Nucleus sampling parameter
          minimum: 0
          maximum: 1
          example: 1
        stream:
          type: boolean
          description: Whether to stream the response (not currently supported)
          default: false
      required:
        - model
        - messages

    ChatMessage:
      type: object
      properties:
        role:
          type: string
          enum: ["system", "user", "assistant", "tool"]
          description: The role of the message sender
        content:
          type: string
          description: The content of the message
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          description: Tool calls made by the assistant (only for assistant messages)
        tool_call_id:
          type: string
          description: ID of the tool call this message is responding to (only for tool messages)
      required:
        - role
        - content

    Tool:
      type: object
      properties:
        type:
          type: string
          enum: ["function"]
        function:
          $ref: '#/components/schemas/FunctionDefinition'
      required:
        - type
        - function

    FunctionDefinition:
      type: object
      properties:
        name:
          type: string
          description: |
            Name of the function. For MCP tools, use namespaced format: "server_name::tool_name"
          example: "get_weather"
        description:
          type: string
          description: Description of what the function does
          example: "Get current weather for a location"
        parameters:
          type: object
          description: JSON Schema for the function parameters
          example:
            type: "object"
            properties:
              location:
                type: "string"
                description: "City name"
            required: ["location"]
      required:
        - name
        - description
        - parameters

    ToolCall:
      type: object
      properties:
        id:
          type: string
          description: Unique identifier for this tool call
          example: "call_abc123"
        type:
          type: string
          enum: ["function"]
        function:
          $ref: '#/components/schemas/FunctionCall'
      required:
        - id
        - type
        - function

    FunctionCall:
      type: object
      properties:
        name:
          type: string
          description: Name of the function to call
          example: "get_weather"
        arguments:
          type: string
          description: JSON string of arguments to pass to the function
          example: '{"location": "San Francisco"}'
      required:
        - name
        - arguments

    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
          description: Unique identifier for the completion
          example: "chatcmpl-123abc"
        object:
          type: string
          enum: ["chat.completion"]
        created:
          type: integer
          description: Unix timestamp of completion creation
          example: 1694268190
        model:
          type: string
          description: Model used for the completion
          example: "aws:anthropic.claude-sonnet-4-20250514-v1:0"
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatChoice'
          minItems: 1
        usage:
          $ref: '#/components/schemas/Usage'
      required:
        - id
        - object
        - created
        - model
        - choices

    ChatChoice:
      type: object
      properties:
        index:
          type: integer
          description: Index of this choice
          example: 0
        message:
          $ref: '#/components/schemas/AssistantMessage'
        finish_reason:
          type: string
          enum: ["stop", "length", "tool_calls", "content_filter"]
          description: Reason the completion finished
      required:
        - index
        - message
        - finish_reason

    AssistantMessage:
      type: object
      properties:
        role:
          type: string
          enum: ["assistant"]
        content:
          type: string
          description: The response content (empty if tool_calls present)
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          description: Tools the assistant wants to call
      required:
        - role
        - content

    Usage:
      type: object
      properties:
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt
          example: 50
        completion_tokens:
          type: integer
          description: Number of tokens in the completion
          example: 20
        total_tokens:
          type: integer
          description: Total tokens used
          example: 70
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens

    Error:
      type: object
      properties:
        error:
          type: object
          properties:
            message:
              type: string
              description: Human-readable error message
            type:
              type: string
              description: Error type/category
            code:
              type: string
              description: Error code
            param:
              type: string
              description: Parameter that caused the error (if applicable)
          required:
            - message
            - type
      required:
        - error

  responses:
    BadRequestError:
      description: Invalid request parameters
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            error:
              message: "Invalid model specified"
              type: "invalid_request_error"
              code: "invalid_model"

    UnauthorizedError:
      description: Authentication token missing, invalid, or expired
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            error:
              message: "Invalid token"
              type: "invalid_request_error"
              code: "invalid_token"

    ForbiddenError:
      description: Access denied - insufficient permissions
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            error:
              message: "Access denied"
              type: "permission_error"
              code: "forbidden"

    RateLimitError:
      description: Rate limit exceeded
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            error:
              message: "Rate limit exceeded"
              type: "rate_limit_error"
              code: "rate_limit_exceeded"

    ContentFilteredError:
      description: Request blocked by content filtering
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            error:
              message: "Content policy violation"
              type: "content_filter_error"
              code: "content_filtered"

    InternalServerError:
      description: Internal server error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            error:
              message: "Internal server error"
              type: "server_error"
              code: "internal_error"

    ServiceUnavailableError:
      description: Service temporarily unavailable
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          example:
            error:
              message: "Service temporarily unavailable"
              type: "server_error"
              code: "service_unavailable"

# Implementation Notes for Client Developers
x-implementation-notes: |
  ## Authentication Implementation
  
  ```javascript
  // Get token using appleconnect
  const { spawn } = require('child_process');
  
  function getFloodgateToken() {
    return new Promise((resolve, reject) => {
      const cmd = spawn('/usr/local/bin/appleconnect', [
        'getToken', '-C', 'hvys3fcwcteqrvw3qzkvtk86viuoqv',
        '--token-type=oauth', '--interactivity-type=none',
        '-E', 'prod', '-G', 'pkce',
        '-o', 'openid,dsid,accountname,profile,groups'
      ]);
      
      let output = '';
      cmd.stdout.on('data', (data) => { output += data.toString(); });
      cmd.on('close', (code) => {
        if (code !== 0) {
          reject(new Error('Failed to get token'));
          return;
        }
        const tokens = output.trim().split(/\s+/);
        resolve(tokens[tokens.length - 1]);  // Last token is auth token
      });
    });
  }
  ```
  
  ## Tool Execution Pattern
  
  ```javascript
  // Example tool execution flow
  async function chatWithTools(messages, tools) {
    const response = await fetch('/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'aws:anthropic.claude-sonnet-4-20250514-v1:0',
        messages,
        tools
      })
    });
    
    const completion = await response.json();
    const choice = completion.choices[0];
    
    if (choice.finish_reason === 'tool_calls') {
      // Execute tools and continue conversation
      const toolResults = await Promise.all(
        choice.message.tool_calls.map(async (toolCall) => {
          const result = await executeToolCall(toolCall);
          return {
            role: 'tool',
            content: result,
            tool_call_id: toolCall.id
          };
        })
      );
      
      // Continue conversation with tool results
      return chatWithTools([
        ...messages,
        choice.message,
        ...toolResults
      ], tools);
    }
    
    return choice.message.content;
  }
  ```
  
  ## MCP Integration Example
  
  ```javascript
  // Convert MCP tool to OpenAI format
  function convertMCPToolToOpenAI(mcpTool, serverName) {
    return {
      type: 'function',
      function: {
        name: `${serverName}::${mcpTool.name}`,
        description: mcpTool.description,
        parameters: mcpTool.inputSchema
      }
    };
  }
  
  // Execute MCP tool call
  async function executeMCPTool(serverName, toolName, args) {
    const mcpClient = mcpClients.get(serverName);
    if (!mcpClient) {
      throw new Error(`MCP server ${serverName} not connected`);
    }
    
    const result = await mcpClient.callTool(toolName, args);
    return result.content[0].text;  // Extract text content
  }
  ```
  
  ## Error Handling Best Practices
  
  - Always check for 401 responses and refresh tokens automatically
  - Implement exponential backoff for 5xx errors
  - Handle 429 rate limit errors with appropriate delays
  - Cache tokens securely and refresh before expiration
  - Validate tool parameters before sending to avoid 400 errors
  
  ## Model Selection
  
  Use the `/models` endpoint to discover available models. Model availability and naming varies by configuration:
  - Claude models may use format: `aws:anthropic.claude-{version}-{date}-v{revision}:0`
  - OpenAI models may use standard names: `gpt-4o`, `gpt-3.5-turbo`
  - Custom models may use any naming convention: `custom-model-v1`, `apple-internal-model`
  
  Always query the models endpoint rather than hardcoding model names.